{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a03723e-78ae-4150-ba22-e2e485b95cdb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ipyleaflet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\danie\\EY-Open-Science-Data-Challenge\\Level1.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danie/EY-Open-Science-Data-Challenge/Level1.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danie/EY-Open-Science-Data-Challenge/Level1.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Visualization\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/danie/EY-Open-Science-Data-Challenge/Level1.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mipyleaflet\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danie/EY-Open-Science-Data-Challenge/Level1.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danie/EY-Open-Science-Data-Challenge/Level1.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mIPython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdisplay\u001b[39;00m \u001b[39mimport\u001b[39;00m Image\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ipyleaflet'"
     ]
    }
   ],
   "source": [
    "# Supress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Visualization\n",
    "import ipyleaflet\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "import seaborn as sns\n",
    "\n",
    "# Data Science\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Feature Engineering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score,classification_report,confusion_matrix\n",
    "\n",
    "# Planetary Computer Tools\n",
    "import pystac\n",
    "import pystac_client\n",
    "import odc\n",
    "from pystac_client import Client\n",
    "from pystac.extensions.eo import EOExtension as eo\n",
    "from odc.stac import stac_load\n",
    "import planetary_computer as pc\n",
    "pc.settings.set_subscription_key('')\n",
    "\n",
    "# Others\n",
    "import requests\n",
    "import rich.table\n",
    "from itertools import cycle\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b031607b-9e71-46c8-beb1-3610ab59c56a",
   "metadata": {},
   "source": [
    "### Feature Scaling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2140c8-3fed-49a4-b9c5-7378c12c5784",
   "metadata": {},
   "source": [
    "<p align=\"justify\"> Before initiating the model training we may have to execute different data pre-processing steps. Here we are demonstrating the scaling of VV and VH variable by using Standard Scaler.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d859a23d-be08-4a7c-b27b-1a4afb03feb5",
   "metadata": {},
   "source": [
    "<p align = \"justify\">Feature Scaling is a data preprocessing step for numerical features. Many machine learning algorithms like Gradient descent methods, KNN algorithm, linear and logistic regression, etc. require data scaling to produce good results. Scikit learn provides functions that can be used to apply data scaling. Here we are using Standard Scaler.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a85328e-bef5-4b81-b7a0-443557387e0c",
   "metadata": {},
   "source": [
    "<h4 style=\"color:rgb(195, 52, 235)\"><strong>Tip 4 </strong></h4>\n",
    "<p align=\"justify\">Participants might explore other feature scaling techniques like Min Max Scaler, Max Absolute Scaling, Robust Scaling etc.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1506aede-aca0-4acc-a9b7-c7547dd9ed0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1de27d-2b8b-4a3d-bf83-66f69f435402",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e978bb-a1af-48d7-ae11-6912bbe45adf",
   "metadata": {},
   "source": [
    "<p justify =\"align\">Now that we have the data in a format appropriate for machine learning, we can begin training a model. In this demonstration notebook, we have used a binary logistic regression model from the scikit-learn library. This library offers a wide range of other models, each with the capacity for extensive parameter tuning and customization capabilities.</p>\n",
    "\n",
    "<p justify =\"align\">Scikit-learn models require separation of predictor variables and the response variable. You have to store the predictor variables in array X and the response variable in the array Y. You must make sure not to include the response variable in array X. It also doesn't make sense to use latitude and longitude as predictor variables in such a confined area, so we drop those too.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "888f7099-afbf-47d5-a214-00ae0e11bf66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(solver='lbfgs')\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87f54ac-ccd9-43a0-a53c-3403ee56c43d",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c940c3e9-caa0-4081-9941-372082cad66b",
   "metadata": {},
   "source": [
    "Now that we have trained our model , all that is left is to evaluate it. For evaluation we will generate the classification report and will plot the confusion matrix. Scikit-learn provides many other metrics that can be used for evaluation. You can even write a code on your own."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ad0925-b550-4b26-ae96-2ec160ae3dff",
   "metadata": {
    "tags": []
   },
   "source": [
    "### In-Sample Evaluation\n",
    "<p align=\"Jutisfy\"> We will be generating a classification report and a confusion matrix for the training data. It must be stressed that this is in-sample performance testing , which is the performance testing on the training dataset. These metrics are NOT truly indicative of the model's performance. You should wait to test the model performance on the test data before you feel confident about your model.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab57db4-c7e8-4ff2-ac31-eea3f7eab64f",
   "metadata": {},
   "source": [
    "In this section, we make predictions on the training set and store them in the <b><i>insample_ predictions</i></b> variable. A confusion matrix is generated to gauge the robustness of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7a4196f-226e-4c52-8a64-bc00535bc97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "insample_predictions = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e131de89-a22d-4912-9f9b-6c7a12769c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insample Accuracy 60.95%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Non Rice       0.55      0.62      0.58       184\n",
      "        Rice       0.67      0.60      0.63       236\n",
      "\n",
      "    accuracy                           0.61       420\n",
      "   macro avg       0.61      0.61      0.61       420\n",
      "weighted avg       0.62      0.61      0.61       420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Insample Accuracy {0:.2f}%\".format(100*accuracy_score(insample_predictions,y_train)))\n",
    "print(classification_report(insample_predictions,y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e847aa72-37b8-498b-bd63-4130d1366b7e",
   "metadata": {},
   "source": [
    "<p> For plotting a confusion matrix we define the function <b><i>plot_confusion_matrix</i></b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb97e054-6e73-4d90-89e2-36ce094721f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(true_value,predicted_value,title,labels):\n",
    "    '''\n",
    "    Plots a confusion matrix.\n",
    "    Attributes:\n",
    "    true_value - The ground truth value for comparision.\n",
    "    predicted_value - The values predicted by the model.\n",
    "    title - Title of the plot.\n",
    "    labels - The x and y labels of the plot.\n",
    "    '''\n",
    "    cm = confusion_matrix(true_value,predicted_value)\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True, fmt='g', ax=ax, cmap='Blues');\n",
    "    ax.set_xlabel('Predicted labels');\n",
    "    ax.set_ylabel('True labels'); \n",
    "    ax.set_title(title); \n",
    "    ax.xaxis.set_ticklabels(labels); \n",
    "    ax.yaxis.set_ticklabels(labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c77326-b7d5-4dc4-8101-96bece8aceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_train,insample_predictions,\"Model Level 1: Logistic\\nRegression Model In-Sample Results\",['Rice', 'Non Rice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fd9f2d-1add-499a-b692-f616ec02871d",
   "metadata": {},
   "source": [
    "### Out-Sample Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9e1681-0cae-42c1-ad00-0ad3bb7eca71",
   "metadata": {},
   "source": [
    "When evaluating a machine learning model, it is essential to correctly and fairly evaluate the model's ability to generalize. This is because models have a tendency to overfit the dataset they are trained on. To estimate the out-of-sample performance, we will predict on the test data now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7324d1-35fd-463f-9734-f2ad1552ae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "outsample_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdec320-a85c-49b9-8177-a65d5b85317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy {0:.2f}%\".format(100*accuracy_score(outsample_predictions, y_test)))\n",
    "print(classification_report(y_test, outsample_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5ed827-f3b8-47a2-865c-61bd2cd9621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y_test, outsample_predictions,\"Model Level 1: Logistic\\nRegression Model Out-Sample Results\",['Rice', 'Non Rice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0bd4a4-5976-4a37-8f5b-fe46cf841e1f",
   "metadata": {},
   "source": [
    "From the above, we see that the model is able to achieve an F1 score of <b>0.57</b>. This is not a very good score, so your goal is to improve this score.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2629f3f5-5a51-45d7-9c68-75b969101405",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287c178f-1113-4456-b1c6-3188273bc1f3",
   "metadata": {},
   "source": [
    "Once you are happy with your model, you can make a submission. To make a submission, you will need to use your model to make predictions about the presence of rice crops for a set of test coordinates we have provided in the <a href=\"https://challenge.ey.com/api/v1/storage/admin-files/6847912254281276-63ca8b5ab12e510013520e2b-challenge_1_submission_template.csv\"><b>\"challenge_1_submission_template.csv\"</b></a> file and upload the file onto the challenge platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fc4682-5a87-4ccb-9b4d-877221e397e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the coordinates for the submission\n",
    "test_file = pd.read_csv('./Data/challenge_1_submission_template.csv')\n",
    "test_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c5e29a-3bfa-4f5e-ac00-ffbf6b18033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get Sentinel-1-RTC Data\n",
    "time_slice = \"2020-03-20/2020-03-21\"\n",
    "assests = ['vh','vv']\n",
    "vh_vv = []\n",
    "for coordinates in tqdm(test_file['Latitude and Longitude']):\n",
    "    vh_vv.append(get_sentinel_data(coordinates,time_slice,assests))\n",
    "submission_vh_vv_data = pd.DataFrame(vh_vv,columns =['vh','vv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b02ce9-ef4b-4e96-b895-cabca85f2860",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_vh_vv_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb45aca-974a-41e1-a522-36ca202d9af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling \n",
    "submission_vh_vv_data = submission_vh_vv_data.values\n",
    "transformed_submission_data = sc.transform(submission_vh_vv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc34e3a-bfc1-49a0-94bb-ee1e540abe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making predictions\n",
    "final_predictions = model.predict(transformed_submission_data)\n",
    "final_prediction_series = pd.Series(final_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0375e4cd-fdb0-4b82-8508-6ff022061cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining the results into dataframe\n",
    "submission_df = pd.DataFrame({'Latitude and Longitude':test_file['Latitude and Longitude'].values, 'Class of Land':final_prediction_series.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1a563b-c0ed-4e2c-a7fe-08ad59cf1626",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying the sample submission dataframe\n",
    "display(submission_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcec864-4da3-41e7-80da-b77e42a9d810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dumping the predictions into a csv file.\n",
    "submission_df.to_csv(\"challenge_1_submission_rice_crop_prediction.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094c2fba-5ecb-4ea5-a4a5-1fd6a74952cc",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10632df0-a001-4932-8ef9-c7dc9023cc7f",
   "metadata": {},
   "source": [
    "Now that you have learned a basic approach to model training, it’s time to try your own approach! Feel free to modify any of the functions presented in this notebook. We look forward to seeing your version of the model and the results. Best of luck with the challenge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0fca13cb3bcf9c0b7539a43a614a3723784c8f2a6b8aa3fe66a3dae363c8df45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
